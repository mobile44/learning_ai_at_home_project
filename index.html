<html>
<head>
    <style>
        .topbar p {
            background-color: green;
            color: white;
            font-size: 24px;
            font-weight: bold;
            text-align: center;
        }
        p.content {
            text-align: justify;
        }
        p.icon {
            text-align: right;
        }
        .project {
            //width: 320px;
            padding: 10px;
            border: 5px solid gray;
            margin: 0;
        }
        .secondbar p {
            background-color: brown;
            color: white;
            font-size: 24px;
            font-weight: bold;
            text-align: center;
        }
        .thirdbar p {
            background-color: blue;
            color: white;
            font-size: 24px;
            font-weight: bold;
            text-align: center;
        }
        .ptbar p {
            background-color: rgb(104, 135, 30);
            color: white;
            font-size: 24px;
            font-weight: bold;
            text-align: center;
        }
        .rtbar p {
            background-color: rgb(96, 30, 135);
            color: white;
            font-size: 24px;
            font-weight: bold;
            text-align: center;
        }
        .tfbar p {
            background-color: rgb(12, 116, 185);
            color: white;
            font-size: 24px;
            font-weight: bold;
            text-align: center;
        }
        .row {
            display: flex;
        }
        .column {
            flex: 50%;
        }
        table {
            width: 100%;
        }
        th {
            background-color: Gainsboro;
            font-size: 16px;
            font-weight: bold;
        }
        .stacks {
            position: relative;
            top: 0;
            left: 0;
        }
        .stack {
            position: absolute;
            top: 260px;
            left: 450px;
        }
    </style>
</head>
<body>
    <div class="topbar">
        <p>Learning AI at home with well configured JetBot (Jetson Nano)</p>
    </div>
    <div class='project'>
        <p class="content">I am interested in technology. However there is no such good place to learn deep learning nearby especially for kids. I have tried differenct ways such as doing it in laptop; colab; and jetson nano etc. They all can allow me doing a certain level of GPU training. However, I find that it is hard to using all different frameworks working together such as Tensorflow; Pytorch; TensorRT and networks such as yolov; resnet and mobilenet in one single platform. In order to make it convenient; portable and simple for kids. I make up this project. After development of single platform, I hope to create an innovative way of picking up knowledge with fun activities for kids</p>
        <p class="content">Learning codes, I believe that line by line is the easiest way for kids and Jupyter notebook is the best choice as it can allow you to visualize the result of running codes by line or bunch of lines. Although GPU is preferred, we don't need much as we could use light network or smaller image size to finish one training within the time those kids can stand for. For the cost of hardware, a laptop with GPU of entry level should be US$800 around. However, laptop should be for general multiple purposes and it is hard for kids using purely Linux environment. Colab is very helpful but it is not for TensorRT. Put all together, I choose Jetson nano. First, its cost in $US100 should be affordable for parents or school to invest. It doesn't have hard drive but a micro SD. Since we only need an environment of learning instead of data storage, micro SD is preferrable and it is easy to manage. By default, Jetbot kit comes with few training chapters for learner to warm up. Jetbot can act as robot with motors; cameras and other I2C componeents. Further Jetson nano can be offline to practice if necessary data has prepared. Therefore I don't see others to beat it.</p>
        <p>If you are planning to let your children or students to learn with Jetbot while you want to use it as a single platform for different AI Experiement Exercises, you can contact me via email. You can make you own choice of picking up the online supplier for Jetson Nano or Jetbot, I guide you configuring the environment based on the standard Jetson Nano package (JetPack 4.4.1). Also, I will keep on to consolidate more examples and debug it to adapt to Jetbot environment if necessary. I have included original URL at the top of each exercise as you may want to find more detail from arthur's original page. For shopping the Jetbot, you can refer to the one as in the photo.</p>
        <p>Here I want to say thank you to those guys who originally publish the exercises which are very helpful for me. I hope to make it further to benefit more learners in future especially for kids.</p>
        <p class="icon"><img src="images/contact.jpg" alt="MyIcon" width="486" height="59"/></p>
    </div>
    <div class="row">
        <div class="column">
            <div style="position: relative; left: 0; top: 0;">
                <img src="images/JetsonNano.jpg" alt="Jetson Nano" width="540" height="450" class="stacks"/>
                <img src="images/jetbot.jpg" alt="JetBot" width="128" height="180" class="stack"/>
            </div>
        </div>
        <div class="column">
            <table>
                <tr><th colspan=2>Technical Specifications & Necessary Peripherals</th></tr>
                <tr><td>GPU</td><td>128-core Maxwell</td></tr>
                <tr><td>CPU</td><td>Quad-core ARM A57 @ 1.43 GHz</td></tr>
                <tr><td>Memory</td><td>4 GB 64-bit LPDDR4 25.6 GB/s</td></tr>
                <tr><td>Storage	microSD</td><td>Micro SD (64GB minimum)</td></tr>
                <tr><td>Video Encode</td><td>4K @ 30 | 4x 1080p @ 30 | 9x 720p @ 30 (H.264/H.265)</td></tr>
                <tr><td>Video Decode</td><td>4K @ 60 | 2x 4K @ 30 | 8x 1080p @ 30 | 18x 720p @ 30 (H.264/H.265)</td></tr>
                <tr><td>Camera</td><td>2x MIPI CSI-2 DPHY lanes</td></tr>
                <tr><td>Connectivity</td><td>Gigabit Ethernet, M.2 Key E</td></tr>
                <tr><td>Display</td><td>HDMI and display port</td></tr>
                <tr><td>USB</td><td>4x USB 3.0, USB 2.0 Micro-B</td></tr>
                <tr><td>Others</td><td>GPIO, I2C, I2S, SPI, UART</td></tr>
                <tr><td>Mechanical</td><td>69 mm x 45 mm, 260-pin edge connector</td></tr>
                <tr><td>WiFi</td><td>Dual Bands - Intel 8265AC 8265NGW with wires and antenna</td></tr>
                <tr><td>Case</td><td>JetBot Case</td></tr>
                <tr><td>Fan</td><td>Standard Fan for Jetson Nano</td></tr>
                <tr><td>Power</td><td>5V Charger</td></tr>
                <tr><td>Keyboard</td><td>Standard</td></tr>
                <tr><td>Mouse</td><td>Standard</td></tr>
                <tr><td>Monitor</td><td>Standard with HDMI cable</td></tr>
            </table>
        </div>
    </div>
    <div class="secondbar">
        <p>Software configurations</p>
    </div>
    <div class="row">
        <div class="column">
            <img src="images/Ubuntu.jpg" alt="Ubuntu" width="134" height="95">
            <img src="images/JetPack.jpg" alt="JetPack" width="142" height="89">
            <img src="images/Python.jpg" alt="Python" width="113" height="113">
            <img src="images/PyTorch.jpg" alt="PyTorch" width="191" height="66">
            <img src="images/TensorFlow.jpg" alt="TensorFlow" width="137" height="93">
            <img src="images/Keras.jpg" alt="Keras" width="155" height="82">
            <img src="images/TensorRT.jpg" alt="TensorRT" width="159" height="80">
            <img src="images/OpenCV.jpg" alt="OpenCV" width="101" height="125">
            <img src="images/Jupyter.jpg" alt="Jupyter" width="104" height="121">
            <img src="images/Onnx.jpg" alt="Onnx" width="185" height="68">
        </div>
        <div class="column">
            <table>
                <tr><th colspan=2>Software & Applications</th></tr>
                <tr><td>ipython</td><td>7.16.1</td></tr>
                <tr><td>jetbot</td><td>0.4.1</td></tr>
                <tr><td>Jetson.GPIO</td><td>2.0.11</td></tr>
                <tr><td>jupyterlab</td><td>3.0.1</td></tr>
                <tr><td>kaggle</td><td>1.3.9</td></tr>
                <tr><td>Keras</td><td>2.4.3</td></tr>
                <tr><td>matplotlib</td><td>3.3.3</td></tr>
                <tr><td>notebook</td><td>6.1.6</td></tr>
                <tr><td>numpy</td><td>1.19.4</td></tr>
                <tr><td>object-detection</td><td>0.1</td></tr>
                <tr><td>onnxoptimizer</td><td>1.6.0</td></tr>
                <tr><td>onnxruntime-gpu-tensorrt</td><td>0.24.0</td></tr>
                <tr><td>opencv</td><td>4.5.1</td></tr>
                <tr><td>pandas</td><td>1.1.5</td></tr>
                <tr><td>tensorboard</td><td>2.4.0</td></tr>
                <tr><td>tensorflow</td><td>2.3.1+nv20.12</td></tr>
                <tr><td>tensorrt</td><td>7.1.3.0</td></tr>
                <tr><td>torch</td><td>1.7.0</td></tr>
                <tr><td>torch2trt</td><td>0.1.0</td></tr>
                <tr><td>torchvision</td><td>0.8.0a0+291f7e2</td></tr>
            </table>
        </div>
    </div>
    <div class="thirdbar">
        <p>JetBot Example 01 - Basic Motion</p>
    </div>
    <div class="row">
        <div class="column">
            <img src="images/jetbot_01.jpg" alt="Basic Motion" width="528" height="286">
        </div>
        <div class="column">
            <table>
                <tr><th colspan=2>Key Items</th></tr>
                <tr><td>01</td><td>import jetbot library</td></tr>
                <tr><td>02</td><td>set left motor speed</td></tr>
                <tr><td>03</td><td>set right motor speed</td></tr>
                <tr><td>04</td><td>stop motor</td></tr>
                <tr><td>05</td><td>set left and right motors in one command</td></tr>
                <tr><td>06</td><td>iPython</td></tr>
                <tr><td>07</td><td>iPython widgets</td></tr>
                <tr><td>08</td><td>traitlets</td></tr>
                <tr><td>09</td><td>box</td></tr>
                <tr><td>10</td><td>slider</td></tr>
                <tr><td>11</td><td>button</td></tr>
            </table>
        </div>
    </div>
    <div class="thirdbar">
        <p>JetBot Example 02 - Teleoperation</p>
    </div>
    <div class="row">
        <div class="column">
            <img src="images/jetbot_02.jpg" alt="Teleoperation" width="528" height="286">
        </div>
        <div class="column">
            <table>
                <tr><th colspan=2>Key Items</th></tr>
                <tr><td>01</td><td>gamepad connection</td></tr>
                <tr><td>02</td><td>tie traitlets with gamepad</td></tr>
                <tr><td>03</td><td>import camera library</td></tr>
                <tr><td>04</td><td>capture video stream</td></tr>
                <tr><td>05</td><td>apply heartbeat monitor</td></tr>
                <tr><td>06</td><td>capture snapshot</td></tr>
            </table>
        </div>
    </div>
    <div class="thirdbar">
        <p>JetBot Example 03 - Collision avoidance</p>
    </div>
    <div class="row">
        <div class="column">
            <img src="images/jetbot_03.jpg" alt="Collision avoidance" width="528" height="286">
        </div>
        <div class="column">
            <table>
                <tr><th colspan=2>Key Items</th></tr>
                <tr><td>01</td><td>capture photos for training dataset</td></tr>
                <tr><td>02</td><td>import uuid for unique file name</td></tr>
                <tr><td>03</td><td>compress dataset</td></tr>
                <tr><td>04</td><td>train model with neural network</td></tr>
                <tr><td>05</td><td>train with resnet18</td></tr>
                <tr><td>06</td><td>plot the training process</td></tr>
                <tr><td>07</td><td>test with models</td></tr>
                <tr><td>08</td><td>test with resnet18</td></tr>
                <tr><td>09</td><td>accelerate with TensorRT</td></tr>
                <tr><td>10</td><td>accelerate resnet18 model with TensorRT</td></tr>
            </table>
        </div>
    </div>
    <div class="thirdbar">
        <p>JetBot Example 04 - Object Following</p>
    </div>
    <div class="row">
        <div class="column">
            <img src="images/jetbot_04.jpg" alt="Object Following" width="528" height="286">
        </div>
        <div class="column">
            <table>
                <tr><th colspan=2>Key Items</th></tr>
                <tr><td>01</td><td>detect object with model ssd_mobilenet_v2_coco</td></tr>
                <tr><td>02</td><td>tune jetbot to follow object</td></tr>
            </table>
        </div>
    </div>
    <div class="ptbar">
        <p>Machine Learning - PyTorch 01 ResNet Detection</p>
    </div>
    <div class="row">
        <div class="column">
            <img src="images/pt01.jpg" alt="Pytorch01" width="252" height="281">
        </div>
        <div class="column">
            <table>
                <tr><th colspan=2>Summary</th></tr>
                <tr><td>01</td><td>torch</td></tr>
                <tr><td>02</td><td>jason</td></tr>
                <tr><td>03</td><td>numpy</td></tr>
                <tr><td>04</td><td>torchvision</td></tr>
                <tr><td>05</td><td>PIL</td></tr>
                <tr><td>06</td><td>matplotlib</td></tr>
                <tr>
                    <td>-</td>
                    <td>
                        <p>This exercise uses torch with trained model of ResNet to predict image object. We can learn to load label and model; to transform image to tensor cuda and predict the object. At last, we will see how film per second can be run in this hardware specification.</p>
                        <p></p>
                    </td>
                </tr>
            </table>
        </div>
    </div>
    <div class="ptbar">
        <p>Machine Learning - PyTorch 02 using CIFAR dataset to train with self defined CNN</p>
    </div>
    <div class="row">
        <div class="column">
            <img src="images/pt02.jpg" alt="PyTorch02" width="330" height="232">
        </div>
        <div class="column">
            <table>
                <tr><th colspan=2>Summary</th></tr>
                <tr><td>01</td><td>torch</td></tr>
                <tr><td>02</td><td>numpy</td></tr>
                <tr><td>03</td><td>torchvision</td></tr>
                <tr><td>04</td><td>matplotlib</td></tr>
                <tr>
                    <td>-</td>
                    <td>
                        <p>This exercise uses torch to construct a neural network for training with CIFAR dataset. We learn to detect environment whether is with GPU or CPU; to define the parameters for loading dataset; split dataset into training and validating group; print images in one shot; to split color channels; to define neural network architecture; to prepre loss and optimizer rate and to train and evaluate model with dataset. At last, we will see prediction results with self trained model.</p>
                        <p></p>
                    </td>
                </tr>
            </table>
        </div>
    </div>
    <div class="ptbar">
        <p>Machine Learning - PyTorch 03 YOLOV5 Detection</p>
    </div>
    <div class="row">
        <div class="column">
            <img src="images/zidane.jpg" alt="ZIDANE" width="512" height="288">
        </div>
        <div class="column">
            <table>
                <tr><th colspan=2>Key Items</th></tr>
                <tr><td>01</td><td>argparse</td></tr>
                <tr><td>02</td><td>pathlib</td></tr>
                <tr><td>03</td><td>cv2</td></tr>
                <tr><td>04</td><td>time</td></tr>
                <tr><td>05</td><td>torch</td></tr>
                <tr><td>06</td><td>numpy</td></tr>
                <tr>
                    <td>-</td>
                    <td><p>detect.py is default python tool in python5 to predict object. There are 5 pre-trained model such as yolov5s.pt; yolov5m.pt; yolov5l.pt and yolov5x.pt and they don't come with default yolov5 download. When we run the command, it will check against the existnence of model. If it is not found, it will download automatically. Yolov5 provides very simple way to learn dataset annotation; model training and prediction with self-trained model.</p>
                    </td>
                </tr>
            </table>
        </div>
    </div>
    <div class="ptbar">
        <p>Machine Learning - PyTorch 04 ResNet Training</p>
    </div>
    <div class="row">
        <div class="column">
            <img src="images/pt04.jpg" alt="PyTorch04" width="515" height="195">
        </div>
        <div class="column">
            <table>
                <tr><th colspan=2>Key Items</th></tr>
                <tr>
                    <td>-</td>
                    <td>
                        <p>This exercise is an extension of first PyTorch exercise. It is using ImageNet dataset to train with ResNet the pre-trained model weights. The default epoch is 10 but you can try 25 after first train. Then you can compare any improvement of accuracy.</p>
                    </td>
                </tr>
            </table>
        </div>
    </div>
    <div class="ptbar">
        <p>Machine Learning - PyTorch 05 ResNet Training & Prediction</p>
    </div>
    <div class="row">
        <div class="column">
            <img src="images/pt05.jpg" alt="PyTorch05" width="440" height="263">
        </div>
        <div class="column">
            <table>
                <tr><th colspan=2>Key Items</th></tr>
                <tr><td>01</td><td>torch</td></tr>
                <tr><td>02</td><td>numpy</td></tr>
                <tr><td>03</td><td>torchvision</td></tr>
                <tr><td>04</td><td>matplotlib</td></tr>
                <tr><td>05</td><td>time</td></tr>
                <tr><td>06</td><td>os</td></tr>
                <tr><td>07</td><td>copy</td></tr>
                <tr>
                    <td>-</td>
                    <td>
                        <p>This exercise is an extension of training of last PyTorch exercise. It is using ImageNet dataset to train with ResNet the pre-trained model weights. The epoch is 25 and tune the learning rate in every 7 epoch. Finally you can find a high accuracy rate at the end of this training.</p>
                    </td>
                </tr>
            </table>
        </div>
    </div>
    <div class="rtbar">
        <p>Machine Learning - TensorRT 01 Prediction with pre-trained ResNet model</p>
    </div>
    <div class="row">
        <div class="column">
            <img src="images/rt01.jpg" alt="TensorRT01" width="242" height="202">
        </div>
        <div class="column">
            <table>
                <tr><th colspan=2>Key Items</th></tr>
                <tr><td>01</td><td>Jetson</td></tr>
                <tr><td>02</td><td>PIL</td></tr>
                <tr><td>03</td><td>matplotlib</td></tr>
                <tr>
                    <td>-</td>
                    <td>
                        <p>This exercise uses jetson library which has been built in with TensorRT. TensorRT is an accelerator of CNN model from TensorFlow or PyTorch. We just use it and can detect objects in image. In this exercise we use python to compose a program with loading ResNet for prediction purpose.</p>
                    </td>
                </tr>
            </table>
        </div>
    </div>
    <div class="tfbar">
        <p>Machine Learning - TensorFlow 01 Prediction with pre-trained MobileNet model</p>
    </div>
    <div class="row">
        <div class="column">
            <img src="images/tf01.jpg" alt="TensorFlow01" width="467" height="313">
        </div>
        <div class="column">
            <table>
                <tr><th colspan=2>Key Items</th></tr>
                <tr><td>01</td><td>os</td></tr>
                <tr><td>02</td><td>pathlib</td></tr>
                <tr><td>03</td><td>matplotlib</td></tr>
                <tr><td>04</td><td>io</td></tr>
                <tr><td>05</td><td>scipy</td></tr>
                <tr><td>06</td><td>numpy</td></tr>
                <tr><td>07</td><td>six</td></tr>
                <tr><td>08</td><td>PIL</td></tr>
                <tr><td>09</td><td>tensorflow</td></tr>
                <tr><td>10</td><td>object-detection</td></tr>
                <tr>
                    <td>-</td>
                    <td>
                        <p>This exercise goes through more steps than PyTorch or TensorRT. Processes are divided into selection of light model; an image; pose of human and object labels. Then, it downloads the pre-trained model and load into tensor. Next step is to transfer image into tensor numpy and pass to tensor to detect the keypoints with model pre-loaded. At last, objects in image are labeled; stated with percentage and highlighted with bounding box.</p>
                    </td>
                </tr>
            </table>
        </div>
    </div>
    <div class="tfbar">
        <p>Machine Learning - TensorFlow 02 Train & Prediction with ResNet</p>
    </div>
    <div class="row">
        <div class="column">
            <img src="images/duckies_test.gif" alt="TensorFlow02" width="484" height="404">
        </div>
        <div class="column">
            <table>
                <tr><th colspan=2>Key Items</th></tr>
                <tr><td>01</td><td>matplotlib</td></tr>
                <tr><td>02</td><td>os</td></tr>
                <tr><td>03</td><td>pathlib</td></tr>
                <tr><td>04</td><td>random</td></tr>
                <tr><td>05</td><td>io</td></tr>
                <tr><td>06</td><td>imageio</td></tr>
                <tr><td>07</td><td>glob</td></tr>
                <tr><td>08</td><td>scipy</td></tr>
                <tr><td>09</td><td>numpy</td></tr>
                <tr><td>10</td><td>six</td></tr>
                <tr><td>11</td><td>PIL</td></tr>
                <tr><td>12</td><td>IPython</td></tr>
                <tr><td>13</td><td>tensorflow</td></tr>
                <tr><td>14</td><td>object-detection</td></tr>
                <tr>
                    <td>-</td>
                    <td>
                        <p>This exercise shows to train object with annotation. Some parts are similar to last exercise. The customized dataset is a rubber duck. Images are annotated with a bounding box and class label. Also, they are loaded into a numpy variable. Since here is not colab, annotation have been prepared instead of adding it in notebook. Then there is process to make all in tensor. In order to ensure the dateset is in right place, images with annotation and bounding box are displayed. Pre-trained model ResNet and checkpoints are downloaded beforehand. Hence it is just to load and configured the model builder. AFter that, it is to train with 100 batches. The last is to preidct the test images. Since the images are split from one shot of video, we will use gif creator to group all as a video effect.</p>
                    </td>
                </tr>
            </table>
        </div>
    </div>
</body>
</html>
